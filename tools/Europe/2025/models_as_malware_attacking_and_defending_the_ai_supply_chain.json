{
  "Tool Name": "Models as Malware: Attacking and Defending the AI Supply Chain",
  "Description": "The open source model development community is growing exponentially, with over 1.8 million publicly accessible models on HuggingFace today.\nInstitutions and individuals alike leverage this platform to access and share state-of-the-art AI for deployment on a wide range of infrastructure, from personal devices to production systems.\nUnder the hood, many AI model formats are both data (weights) and code (architecture), with most users relying on easy but vulnerable serialization formats to distribute models â€” and attackers are taking notice, embedding payloads in models to connect to C2 servers:\n- https://thehackernews.com/2025/02/malicious-ml-models-found-on-hugging.html (Feb 2025)\n- https://arstechnica.com/security/2024/03/hugging-face-the-github-of-ai-hosted-code-that-backdoored-user-devices/ (Mar 2024)",
  "Github URL": "https://github.com/ShenaoW/awesome-llm-supply-chain-security",
  "Tracks": [
    "Arsenal Labs"
  ],
  "Speakers": [
    "Nathan Chang",
    "Roee Landesman"
  ],
  "Region": "Europe",
  "Year": "2025"
}