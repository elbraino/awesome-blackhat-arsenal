{
  "Tool Name": "MIPSEval: Multi-turn LLM Evaluation of LLM Safety",
  "Description": "MIPSEval is an automated multi-turn LLM safety evaluation framework that tests language models against jailbreaking, prompt injection, and guardrail bypass techniques. It enables continuous, repeatable safety assessments of both base models and LLM-powered applications, providing quick and precise evaluation after any model or system prompt changes.",
  "Github URL": "https://github.com/stratosphereips/MIPSEval",
  "Tracks": [
    "AI, ML & Data Science"
  ],
  "Speakers": [
    "Muris SladiÄ‡",
    "Sebastian Garcia"
  ],
  "Year": "2025",
  "Location": "Europe"
}
