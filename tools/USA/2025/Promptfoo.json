{
  "Tool Name": "Promptfoo",
  "Speakers": [
    "Ian Webster",
    "Michael D'Angelo",
    "Vanessa Sauter"
  ],
  "Tracks": [
    "AI",
    "ML & Data Science",
    "Arsenal Lab"
  ],
  "Event": "BH-ARSENAL",
  "Github URL": "https://github.com/promptfoo/promptfoo",
  "Description": "Promptfoo is an offensive security tool designed to test applications built on large language models (LLMs). Leveraging the latest adversarial ML research, Promptfoo uses ablated, fine-tuned models to generate unique, adversarial payloads to find and exploit more than 50 types of vulnerabilities in LLM applications. More than 60,000 developers use Promptfoo, including at major companies like Shopify, OpenAI, Anthropic, Twilio, and DoorDash.\n\nPromptfoo is unique in its capabilities because it uses specialized adversarial agents trained to probe specific risks in AI applications. Rather than relying on generic jailbreaks or known exploits, these agents analyze your application's unique attack surface - its specific use cases, integrated tools, data sources, and security boundaries. Promptfoo then generates targeted probes to identify vulnerabilities in your applications.\n\nThe tests cover application-level categories such as PII/data leaks, access control issues via agentic tool use, as well as model-level risks like jailbreaks/injections and other harmful outputs.",
  "Year": "2025",
  "Location": "USA"
}